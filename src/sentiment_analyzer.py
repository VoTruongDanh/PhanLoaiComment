"""
Tool ph√¢n t√≠ch sentiment cho comments TikTok
ƒê√°nh gi√° c·ªôt text v√† t·∫°o c·ªôt sentiment:
- 1: t√≠ch c·ª±c (positive)
- 0: trung t√≠nh (neutral)
- -1: ti√™u c·ª±c (negative)
"""

import pandas as pd
import numpy as np
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from transformers import pipeline
import torch
from tqdm import tqdm
import warnings
import sys
import os
import re
import time

# Try import Gemini
try:
    import google.generativeai as genai
    HAS_GEMINI = True
except ImportError:
    HAS_GEMINI = False
    print("‚ö†Ô∏è  google-generativeai ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t. Ch·∫°y: pip install google-generativeai")

# Fix encoding for Windows console
if sys.platform == 'win32':
    try:
        # Set console to UTF-8
        os.system('chcp 65001 >nul 2>&1')
        sys.stdout.reconfigure(encoding='utf-8') if hasattr(sys.stdout, 'reconfigure') else None
        sys.stderr.reconfigure(encoding='utf-8') if hasattr(sys.stderr, 'reconfigure') else None
    except:
        pass

warnings.filterwarnings('ignore')

# T·ª´ kh√≥a t√≠ch c·ª±c ti·∫øng Vi·ªát
POSITIVE_KEYWORDS = [
    'xinh', 'ƒë·∫πp', 'cute', 'd·ªÖ th∆∞∆°ng', 'hay', 't·ªët', 'tuy·ªát', 'vui', 'th√≠ch', 'y√™u',
    'love', 'amazing', 'great', 'good', 'nice', 'beautiful', 'wonderful', 'awesome',
    'th√∫ v·ªã', 'h√†i', 'vui v·∫ª', 'h·∫°nh ph√∫c', 'tuy·ªát v·ªùi', 'xu·∫•t s·∫Øc', 'gi·ªèi', 't√†i',
    'khen', 'khen ng·ª£i', '·ªßng h·ªô', 'ƒë·ªìng √Ω', 'ƒë√∫ng', 'ch√≠nh x√°c', 'chu·∫©n', 'ok', 'okay',
    'kh√¥ng sao', 'k sao', 'ko sao', '·ªïn', 'fine', 'alright', 'xinh qu√°', 'ƒë·∫πp qu√°',
    'ngon', 'ngon l·∫Øm', 'th√≠ch l·∫Øm', 'tuy·ªát v·ªùi', 'xu·∫•t s·∫Øc'
]

# T·ª´ kh√≥a ti√™u c·ª±c ti·∫øng Vi·ªát (m·ªü r·ªông)
NEGATIVE_KEYWORDS = [
    'x·∫•u', 't·ªá', 'd·ªü', 't·ªìi', 'k√©m', 'gh√©t', 'ch√°n', 'bu·ªìn', 'th·∫•t v·ªçng', 't·ª©c',
    'bad', 'terrible', 'awful', 'hate', 'disgusting', 'horrible', 'worst', 'stupid',
    'ngu', 'd·ªët', 'ƒë·∫ßn', 'l∆∞·ªùi', 'v√¥ d·ª•ng', 'ph·∫£n ƒë·ªëi', 'sai', 'kh√¥ng ƒë√∫ng',
    'ch√™', 'ph√™ ph√°n', 'ch·ªâ tr√≠ch', 't·ª©c gi·∫≠n', 'b·ª±c', 'kh√≥ ch·ªãu',
    # Th√™m t·ª´ kh√≥a ti√™u c·ª±c ph·ªï bi·∫øn
    'ch·ªãu', 't·∫©y chay', 'ph·ªët', 'drama', 'scandal', 'l·ªói', 'sai l·∫ßm', 'v·∫•n ƒë·ªÅ',
    'th·∫•t b·∫°i', 'thua', 'thua l·ªó', 'gi·∫£m', 'gi·∫£m doanh thu', 't·ª•t d·ªëc',
    'ƒëi v√†o l√≤ng ƒë·∫•t', 'to√†n ƒëi v√†o l√≤ng ƒë·∫•t', 's·∫≠p', 'ph√° s·∫£n', 'ƒë√≥ng c·ª≠a',
    'c·ª©u tr·ª£', 'tr√≠ch 1k', 'tr√≠ch ti·ªÅn', 'l·ª´a ƒë·∫£o', 'l·ª´a d·ªëi', 'gian d·ªëi',
    'ch√°n gh√©t', 'm·ªát m·ªèi', 'b·ª©c x√∫c', 't·ª©c gi·∫≠n', 'b·ª±c b·ªôi', 'kh√≥ ch·ªãu',
    'kh√¥ng t·ªët', 'kh√¥ng hay', 'kh√¥ng ·ªïn', 'kh√¥ng ƒë∆∞·ª£c', 'd·ªü t·ªá', 't·ªá h·∫°i',
    'ph·∫£n c·∫£m', 'g√¢y s·ªëc', 's·ªëc', 'kinh kh·ªßng', 'kh·ªßng khi·∫øp', 't·ªìi t·ªá',
    't·ªôi nghi·ªáp', 'ƒë√°ng th∆∞∆°ng', 'th·∫•t v·ªçng', 'b·∫•t ng·ªù ti√™u c·ª±c'
]

# C·ª•m t·ª´ ti√™u c·ª±c (ph·∫£i match c·∫£ c·ª•m)
NEGATIVE_PHRASES = [
    'ch·ªãu r·ªìi', 'ch·ªãu th√¥i', 'ch·ªãu lu√¥n', 'ch·ªãu kh√¥ng n·ªïi',
    't·∫©y chay', 't·∫©y chay h·∫øt', 't·∫©y chay lu√¥n',
    'ƒëi v√†o l√≤ng ƒë·∫•t', 'to√†n ƒëi v√†o l√≤ng ƒë·∫•t',
    'c·ª©u tr·ª£', 'tr√≠ch 1k', 'tr√≠ch ti·ªÅn c·ª©u tr·ª£',
    'gi·∫£m doanh thu', 'gi·∫£m an t√¢y',
    'h·∫øt v·ª•', 'h·∫øt chi·∫øn d·ªãch', 'h·∫øt ƒë·ª£t',
    't·ª´ l√∫c v·ª•', 't·ª´ v·ª•',
    'ch∆∞a ch·ª´a', 'ch∆∞a b·ªè',
    'ti√™u chu·∫©n k√©p', 'chu·∫©n k√©p',
    'b√∫ fame', 'l√†m content',
    't·ªëi ng·ªß c√≥ ngon kh√¥ng', 'ng·ªß c√≥ ngon kh√¥ng'
]

# C·ª•m t·ª´ gi·∫£i th√≠ch/th√¥ng tin (neutral indicators)
NEUTRAL_PHRASES = [
    'l√† do', 'l√† v√¨', 'ch·∫Øc l√†', 'c√≥ th·ªÉ l√†', 'c√≥ l·∫Ω l√†',
    'nh√¢n vi√™n', 'nv', 'nh√¢n vi√™n b·∫•m', 'nv b·∫•m', 'nh√¢n vi√™n order',
    'ƒë·∫∑t qua app', 'order qua app', 'qua app', 'ƒë·∫∑t app',
    'note nh∆∞ v·∫≠y', 'ghi ch√∫', 'note l·∫°i', 'ghi note',
    'th∆∞·ªùng l√†', 'th√¥ng th∆∞·ªùng', 'b√¨nh th∆∞·ªùng', 'bthg',
    'kh√¥ng ph·∫£i', 'kh√¥ng ph·∫£i do', 'kh√¥ng ph·∫£i l√†',
    'm√¨nh t·ª´ng', 't·ª´ng l√†m', 't·ª´ng th·∫•y',
    'ƒë√≥ l√†', 'ƒë√¢y l√†', 'c√°i n√†y l√†', 'c√°i ƒë√≥ l√†'
]

# Emoji t√≠ch c·ª±c
POSITIVE_EMOJIS = ['üòä', 'üòç', 'ü•∞', 'üòò', 'üòÅ', 'üòÇ', 'ü§ó', 'üòÑ', 'üòÉ', 'üòÜ', 'üòâ', 
                   'üíï', 'üíñ', 'üíó', 'üíì', 'üíû', '‚ù§Ô∏è', 'üß°', 'üíõ', 'üíö', 'üíô', 
                   'üíú', 'ü§ç', 'üñ§', 'ü§é', 'üíØ', 'üëç', 'üëè', 'üéâ', 'üéä', '‚ú®', 'üåü']

# Emoji ti√™u c·ª±c
NEGATIVE_EMOJIS = ['üò¢', 'üò≠', 'üò§', 'üò†', 'üò°', 'ü§¨', 'üòû', 'üòî', 'üòü', 'üòï', 
                   'üôÅ', '‚òπÔ∏è', 'üò£', 'üòñ', 'üò´', 'üò©', 'üíî', 'üëé', '‚ùå', 'üö´']


class SentimentAnalyzer:
    """Ph√¢n t√≠ch sentiment s·ª≠ d·ª•ng model ƒëa ng√¥n ng·ªØ ho·∫∑c Gemini API"""
    
    def __init__(self, model_name='cardiffnlp/twitter-roberta-base-sentiment-latest', 
                 use_gemini=False, gemini_api_key=None):
        """
        Kh·ªüi t·∫°o sentiment analyzer
        
        Args:
            model_name: T√™n model t·ª´ HuggingFace ho·∫∑c 'gemini-2.5-flash'
                       - 'cardiffnlp/twitter-roberta-base-sentiment-latest': Nhanh, h·ªó tr·ª£ ƒëa ng√¥n ng·ªØ
                       - 'nlptown/bert-base-multilingual-uncased-sentiment': Ch√≠nh x√°c h∆°n, ch·∫≠m h∆°n
                       - 'gemini-2.5-flash': S·ª≠ d·ª•ng Gemini 2.5 Flash API (ch√≠nh x√°c nh·∫•t)
            use_gemini: N·∫øu True, s·ª≠ d·ª•ng Gemini thay v√¨ transformer model
            gemini_api_key: API key cho Gemini (ho·∫∑c l·∫•y t·ª´ env GEMINI_API_KEY)
        """
        self.use_gemini = use_gemini or model_name == 'gemini-2.5-flash'
        self.gemini_model = None
        self.sentiment_pipeline = None
        
        if self.use_gemini:
            if not HAS_GEMINI:
                raise ImportError("google-generativeai ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t. Ch·∫°y: pip install google-generativeai")
            
            # L·∫•y API key t·ª´ parameter ho·∫∑c environment variable
            api_key = gemini_api_key or os.getenv('GEMINI_API_KEY')
            if not api_key:
                raise ValueError("C·∫ßn cung c·∫•p Gemini API key qua parameter gemini_api_key ho·∫∑c bi·∫øn m√¥i tr∆∞·ªùng GEMINI_API_KEY")
            
            print("ƒêang kh·ªüi t·∫°o Gemini 2.5 Flash...")
            try:
                genai.configure(api_key=api_key)
                # Th·ª≠ d√πng gemini-2.0-flash-exp (model m·ªõi nh·∫•t), fallback v·ªÅ gemini-1.5-flash
                try:
                    self.gemini_model = genai.GenerativeModel('gemini-2.0-flash-exp')
                    print("‚úÖ Gemini 2.0 Flash (experimental) ƒë√£ s·∫µn s√†ng")
                except:
                    self.gemini_model = genai.GenerativeModel('gemini-1.5-flash')
                    print("‚úÖ Gemini 1.5 Flash ƒë√£ s·∫µn s√†ng")
            except Exception as e:
                print(f"‚ùå L·ªói khi kh·ªüi t·∫°o Gemini: {e}")
                raise
        else:
            print(f"ƒêang t·∫£i model: {model_name}...")
            self.device = 0 if torch.cuda.is_available() else -1
            try:
                self.sentiment_pipeline = pipeline(
                    "sentiment-analysis",
                    model=model_name,
                    tokenizer=model_name,
                    device=self.device,
                    return_all_scores=False,
                    truncation=True,
                    max_length=512
                )
                print(f"Model ƒë√£ s·∫µn s√†ng (device: {'GPU' if self.device >= 0 else 'CPU'})")
            except Exception as e:
                print(f"L·ªói khi t·∫£i model: {e}")
                print("ƒêang th·ª≠ model d·ª± ph√≤ng...")
                # Fallback to multilingual model
                self.sentiment_pipeline = pipeline(
                    "sentiment-analysis",
                    model='nlptown/bert-base-multilingual-uncased-sentiment',
                    device=self.device,
                    return_all_scores=False,
                    truncation=True,
                    max_length=512
                )
                print("ƒê√£ t·∫£i model d·ª± ph√≤ng th√†nh c√¥ng")
    
    def _check_keywords_and_emojis(self, text):
        """
        Ki·ªÉm tra t·ª´ kh√≥a v√† emoji ƒë·ªÉ b·ªï sung cho ph√¢n t√≠ch sentiment
        
        Returns:
            tuple: (positive_score, negative_score, neutral_indicator) t·ª´ 0-1
        """
        text_lower = text.lower()
        positive_score = 0
        negative_score = 0
        neutral_indicator = 0
        
        # Ki·ªÉm tra c·ª•m t·ª´ ti√™u c·ª±c tr∆∞·ªõc (quan tr·ªçng h∆°n)
        for phrase in NEGATIVE_PHRASES:
            if phrase in text_lower:
                negative_score += 0.5  # C·ª•m t·ª´ c√≥ tr·ªçng s·ªë cao h∆°n
        
        # Ki·ªÉm tra c·ª•m t·ª´ neutral (gi·∫£i th√≠ch/th√¥ng tin)
        for phrase in NEUTRAL_PHRASES:
            if phrase in text_lower:
                neutral_indicator += 0.4
        
        # Ki·ªÉm tra t·ª´ kh√≥a t√≠ch c·ª±c
        for keyword in POSITIVE_KEYWORDS:
            if keyword in text_lower:
                positive_score += 0.25  # Gi·∫£m tr·ªçng s·ªë t·ª´ng t·ª´ ƒë∆°n
        
        # Ki·ªÉm tra t·ª´ kh√≥a ti√™u c·ª±c
        for keyword in NEGATIVE_KEYWORDS:
            if keyword in text_lower:
                negative_score += 0.25  # Gi·∫£m tr·ªçng s·ªë t·ª´ng t·ª´ ƒë∆°n
        
        # Ki·ªÉm tra emoji t√≠ch c·ª±c
        for emoji in POSITIVE_EMOJIS:
            if emoji in text:
                positive_score += 0.15  # Gi·∫£m tr·ªçng s·ªë emoji
        
        # Ki·ªÉm tra emoji ti√™u c·ª±c
        for emoji in NEGATIVE_EMOJIS:
            if emoji in text:
                negative_score += 0.15
        
        # X·ª≠ l√Ω c√°c tr∆∞·ªùng h·ª£p ƒë·∫∑c bi·ªát
        if any(phrase in text_lower for phrase in ['kh√¥ng sao', 'k sao', 'ko sao', 'khong sao']):
            positive_score += 0.4
        
        # Sarcasm detection: "=))", ":))" trong context ti√™u c·ª±c
        sarcasm_indicators = [':))', '=))', ':)))', '=)))', ':))))', '=))))']
        has_sarcasm = any(indicator in text for indicator in sarcasm_indicators)
        
        # N·∫øu c√≥ sarcasm v√† c√≥ t·ª´ ti√™u c·ª±c -> ti√™u c·ª±c m·∫°nh h∆°n
        if has_sarcasm and negative_score > 0:
            negative_score += 0.3
        
        # N·∫øu c√≥ sarcasm v√† c√≥ t·ª´ t√≠ch c·ª±c trong context ti√™u c·ª±c -> c√≥ th·ªÉ l√† sarcasm
        if has_sarcasm and positive_score > 0 and negative_score > 0.3:
            positive_score = max(0, positive_score - 0.3)  # Gi·∫£m ƒëi·ªÉm t√≠ch c·ª±c
        
        return min(positive_score, 1.0), min(negative_score, 1.0), min(neutral_indicator, 1.0)
    
    def analyze_text_gemini(self, text):
        """
        Ph√¢n t√≠ch sentiment b·∫±ng Gemini API
        
        Args:
            text: ƒêo·∫°n text c·∫ßn ph√¢n t√≠ch
            
        Returns:
            int: 1 (positive), 0 (neutral), -1 (negative)
        """
        if pd.isna(text) or not str(text).strip():
            return 0
        
        try:
            text = str(text).strip()
            
            # Prompt c·∫£i thi·ªán v·ªõi examples v√† h∆∞·ªõng d·∫´n r√µ r√†ng h∆°n
            prompt = f"""Ph√¢n t√≠ch c·∫£m x√∫c comment v√† tr·∫£ v·ªÅ CH·ªà M·ªòT S·ªê: 1, 0, ho·∫∑c -1.

Comment: "{text}"

QUY T·∫ÆC:
- 1 (t√≠ch c·ª±c): Khen, th√≠ch, y√™u, ·ªßng h·ªô, vui, h√†i l√≤ng, t·ªët, ƒë·∫πp, ngon, hay
- 0 (trung t√≠nh): CH·ªà khi l√† c√¢u h·ªèi thu·∫ßn t√∫y, gi·∫£i th√≠ch k·ªπ thu·∫≠t, th√¥ng tin kh√°ch quan KH√îNG c√≥ c·∫£m x√∫c
- -1 (ti√™u c·ª±c): Ch√™, gh√©t, t·ª©c, th·∫•t v·ªçng, ch√°n, ph√™ ph√°n, sarcasm ti√™u c·ª±c (=)), :)) v·ªõi context ti√™u c·ª±c), t·ª´ kh√≥a: ch·ªãu, t·∫©y chay, ph·ªët, drama, c·ª©u tr·ª£, ƒëi v√†o l√≤ng ƒë·∫•t

V√ç D·ª§:
"ngon qu√°" ‚Üí 1
"ƒë·∫πp l·∫Øm" ‚Üí 1  
"t·∫©y chay katinat" ‚Üí -1
"ch·ªãu r·ªìi" ‚Üí -1
"ph·ªët v·ª• 1k" ‚Üí -1
"chi·∫øn d·ªãch ƒëi v√†o l√≤ng ƒë·∫•t =))" ‚Üí -1
"nh√¢n vi√™n b·∫•m note" ‚Üí 0 (gi·∫£i th√≠ch k·ªπ thu·∫≠t)
"ƒë·∫∑t qua app nh∆∞ n√†o?" ‚Üí 0 (c√¢u h·ªèi)
"tui th·∫•y h∆°i ·∫•y :)" ‚Üí -1 (c√≥ c·∫£m x√∫c ti√™u c·ª±c)

QUAN TR·ªåNG: N·∫øu c√≥ B·∫§T K·ª≤ c·∫£m x√∫c (d√π nh·∫π), ƒë·ª´ng ƒë√°nh 0. Ch·ªâ ƒë√°nh 0 khi th·ª±c s·ª± l√† th√¥ng tin kh√°ch quan.

Tr·∫£ v·ªÅ CH·ªà s·ªë: 1, 0, ho·∫∑c -1"""

            response = self.gemini_model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    temperature=0.2,  # TƒÉng m·ªôt ch√∫t ƒë·ªÉ linh ho·∫°t h∆°n
                    max_output_tokens=5,  # Gi·∫£m xu·ªëng v√¨ ch·ªâ c·∫ßn s·ªë
                )
            )
            
            result_text = response.text.strip()
            
            # Parse k·∫øt qu·∫£ - ∆∞u ti√™n t√¨m s·ªë ƒë·∫ßu ti√™n
            import re
            numbers = re.findall(r'-?\d+', result_text)
            if numbers:
                score = int(numbers[0])
                if score in [-1, 0, 1]:
                    return score
            
            # N·∫øu kh√¥ng t√¨m th·∫•y s·ªë, d√πng keyword fallback
            pos_keyword_score, neg_keyword_score, neutral_indicator = self._check_keywords_and_emojis(text)
            
            # N·∫øu c√≥ keyword m·∫°nh, ∆∞u ti√™n keyword
            if neg_keyword_score > 0.5:
                return -1
            elif pos_keyword_score > 0.5 and neg_keyword_score < 0.3:
                return 1
            elif neg_keyword_score > pos_keyword_score + 0.2:
                return -1
            elif pos_keyword_score > neg_keyword_score + 0.2:
                return 1
            # N·∫øu l√† gi·∫£i th√≠ch k·ªπ thu·∫≠t r√µ r√†ng v√† kh√¥ng c√≥ c·∫£m x√∫c -> neutral
            elif neutral_indicator > 0.6 and abs(pos_keyword_score - neg_keyword_score) < 0.2:
                return 0
            # M·∫∑c ƒë·ªãnh: n·∫øu kh√¥ng ch·∫Øc, ∆∞u ti√™n c·∫£m x√∫c h∆°n neutral
            elif neg_keyword_score > 0.2:
                return -1
            elif pos_keyword_score > 0.2:
                return 1
            else:
                return 0
                    
        except Exception as e:
            print(f"L·ªói Gemini khi ph√¢n t√≠ch: {text[:50]}... - {str(e)}")
            # Fallback to keyword-based v·ªõi logic c·∫£i thi·ªán
            pos_keyword_score, neg_keyword_score, neutral_indicator = self._check_keywords_and_emojis(text)
            if neg_keyword_score > 0.4:
                return -1
            elif pos_keyword_score > 0.4 and neg_keyword_score < 0.3:
                return 1
            elif neg_keyword_score > pos_keyword_score + 0.2:
                return -1
            elif pos_keyword_score > neg_keyword_score + 0.2:
                return 1
            elif neutral_indicator > 0.6 and abs(pos_keyword_score - neg_keyword_score) < 0.2:
                return 0
            else:
                # N·∫øu kh√¥ng ch·∫Øc, ∆∞u ti√™n c·∫£m x√∫c h∆°n neutral
                if neg_keyword_score > 0.1:
                    return -1
                elif pos_keyword_score > 0.1:
                    return 1
                return 0
    
    def analyze_text(self, text):
        """
        Ph√¢n t√≠ch sentiment cho m·ªôt ƒëo·∫°n text
        
        Args:
            text: ƒêo·∫°n text c·∫ßn ph√¢n t√≠ch
            
        Returns:
            int: 1 (positive), 0 (neutral), -1 (negative)
        """
        if pd.isna(text) or not str(text).strip():
            return 0
        
        # N·∫øu d√πng Gemini, g·ªçi ph∆∞∆°ng th·ª©c Gemini
        if self.use_gemini and self.gemini_model:
            return self.analyze_text_gemini(text)
        
        try:
            # Gi·ªõi h·∫°n ƒë·ªô d√†i text ƒë·ªÉ tr√°nh l·ªói
            text = str(text)[:512]
            
            # Ki·ªÉm tra t·ª´ kh√≥a v√† emoji tr∆∞·ªõc
            pos_keyword_score, neg_keyword_score, neutral_indicator = self._check_keywords_and_emojis(text)
            
            # N·∫øu c√≥ d·∫•u hi·ªáu neutral m·∫°nh (gi·∫£i th√≠ch/th√¥ng tin), ∆∞u ti√™n neutral
            if neutral_indicator > 0.5 and abs(pos_keyword_score - neg_keyword_score) < 0.4:
                # N·∫øu l√† gi·∫£i th√≠ch/th√¥ng tin v√† kh√¥ng c√≥ c·∫£m x√∫c r√µ r√†ng -> neutral
                return 0
            
            # Ph√¢n t√≠ch b·∫±ng model
            result = self.sentiment_pipeline(text)[0]
            label = result['label'].upper()
            score = result.get('score', 0.5)
            
            # Chuy·ªÉn ƒë·ªïi label th√†nh sentiment score
            model_score = 0
            model_confidence = score
            if '5 STAR' in label or '4 STAR' in label:
                model_score = 1
            elif '1 STAR' in label or '2 STAR' in label:
                model_score = -1
            elif 'POSITIVE' in label or 'POS' in label:
                model_score = 1
            elif 'NEGATIVE' in label or 'NEG' in label:
                model_score = -1
            
            # K·∫øt h·ª£p k·∫øt qu·∫£ model v·ªõi t·ª´ kh√≥a/emoji
            # ∆Øu ti√™n keyword score n·∫øu n√≥ m·∫°nh h∆°n model score
            final_score = model_score
            
            # N·∫øu keyword score r·∫•t m·∫°nh (>0.7), ∆∞u ti√™n keyword
            if neg_keyword_score > 0.7:
                final_score = -1
            elif pos_keyword_score > 0.7 and neg_keyword_score < 0.3:
                final_score = 1
            # N·∫øu keyword score kh√° m·∫°nh (>0.5) v√† model confidence th·∫•p (<0.6), ∆∞u ti√™n keyword
            elif neg_keyword_score > 0.5 and model_confidence < 0.6:
                final_score = -1
            elif pos_keyword_score > 0.5 and neg_keyword_score < 0.3 and model_confidence < 0.6:
                final_score = 1
            # N·∫øu keyword v√† model conflict, ∆∞u ti√™n keyword n·∫øu m·∫°nh h∆°n
            elif neg_keyword_score > pos_keyword_score + 0.4 and model_score >= 0:
                final_score = -1
            elif pos_keyword_score > neg_keyword_score + 0.4 and model_score <= 0:
                final_score = 1
            # N·∫øu keyword score t∆∞∆°ng ƒë·ªëi v√† model confidence cao, gi·ªØ model
            elif abs(pos_keyword_score - neg_keyword_score) < 0.3 and model_confidence > 0.7:
                final_score = model_score
            # N·∫øu keyword difference r√µ r√†ng (>0.3), ƒëi·ªÅu ch·ªânh theo keyword
            elif neg_keyword_score > pos_keyword_score + 0.3:
                final_score = -1
            elif pos_keyword_score > neg_keyword_score + 0.3:
                final_score = 1
            
            # ƒê·∫øm s·ªë emoji t√≠ch c·ª±c v√† ti√™u c·ª±c (b·ªï sung)
            pos_emoji_count = sum(1 for emoji in POSITIVE_EMOJIS if emoji in text)
            neg_emoji_count = sum(1 for emoji in NEGATIVE_EMOJIS if emoji in text)
            
            # N·∫øu c√≥ nhi·ªÅu emoji ti√™u c·ª±c, tƒÉng c∆∞·ªùng ti√™u c·ª±c
            if neg_emoji_count >= 2 and final_score >= 0:
                final_score = -1
            # N·∫øu c√≥ nhi·ªÅu emoji t√≠ch c·ª±c v√† kh√¥ng c√≥ t·ª´ ti√™u c·ª±c m·∫°nh, t√≠ch c·ª±c
            elif pos_emoji_count >= 2 and neg_keyword_score < 0.4 and final_score <= 0:
                final_score = 1
            
            # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p neutral: n·∫øu c√≥ neutral indicator v√† kh√¥ng c√≥ c·∫£m x√∫c r√µ r√†ng
            if neutral_indicator > 0.4 and abs(final_score) == 1:
                # N·∫øu l√† gi·∫£i th√≠ch/th√¥ng tin nh∆∞ng c√≥ c·∫£m x√∫c -> gi·∫£m ƒë·ªô m·∫°nh
                if final_score == 1 and pos_keyword_score < 0.5:
                    final_score = 0
                elif final_score == -1 and neg_keyword_score < 0.5:
                    final_score = 0
            
            return final_score
                
        except Exception as e:
            print(f"L·ªói khi ph√¢n t√≠ch: {text[:50]}... - {str(e)}")
            return 0
    
    def analyze_batch_gemini(self, texts, batch_size=20, progress_callback=None):
        """
        Ph√¢n t√≠ch sentiment b·∫±ng Gemini v·ªõi batch processing (nhanh h∆°n)
        G·ª≠i nhi·ªÅu comments c√πng l√∫c trong 1 request
        """
        results = []
        total_batches = (len(texts) + batch_size - 1) // batch_size
        
        if progress_callback is None:
            try:
                progress_range = tqdm(range(0, len(texts), batch_size), desc="Ph√¢n t√≠ch sentiment (Gemini)")
            except:
                progress_range = range(0, len(texts), batch_size)
        else:
            progress_range = range(0, len(texts), batch_size)
        
        for batch_idx, i in enumerate(progress_range):
            if progress_callback:
                progress_callback(batch_idx + 1, total_batches)
            
            batch_texts = texts[i:i+batch_size].tolist()
            batch_scores = []
            
            # T·∫°o batch prompt cho nhi·ªÅu comments c√πng l√∫c
            comments_list = []
            for idx, text in enumerate(batch_texts):
                if pd.isna(text) or not str(text).strip():
                    batch_scores.append(0)
                    continue
                
                text_clean = str(text).strip()[:500]  # Gi·ªõi h·∫°n ƒë·ªô d√†i
                comments_list.append(f"{idx + 1}. \"{text_clean}\"")
            
            if not comments_list:
                results.extend([0] * len(batch_texts))
                continue
            
            # Prompt t·ªëi ∆∞u cho batch processing
            prompt = f"""Ph√¢n t√≠ch c·∫£m x√∫c c√°c comments sau v√† tr·∫£ v·ªÅ CH·ªà C√ÅC S·ªê, m·ªói d√≤ng 1 s·ªë (1, 0, ho·∫∑c -1) t∆∞∆°ng ·ª©ng v·ªõi t·ª´ng comment theo th·ª© t·ª±.

Comments:
{chr(10).join(comments_list)}

QUY T·∫ÆC:
- 1: Khen, th√≠ch, y√™u, ·ªßng h·ªô, vui, h√†i l√≤ng, t·ªët, ƒë·∫πp, ngon
- 0: CH·ªà khi l√† c√¢u h·ªèi thu·∫ßn t√∫y ho·∫∑c gi·∫£i th√≠ch k·ªπ thu·∫≠t KH√îNG c√≥ c·∫£m x√∫c
- -1: Ch√™, gh√©t, t·ª©c, th·∫•t v·ªçng, ch√°n, ph√™ ph√°n, sarcasm ti√™u c·ª±c (=)), :)), t·ª´: ch·ªãu, t·∫©y chay, ph·ªët, drama, c·ª©u tr·ª£

QUAN TR·ªåNG: N·∫øu c√≥ B·∫§T K·ª≤ c·∫£m x√∫c (d√π nh·∫π), ƒë·ª´ng ƒë√°nh 0.

Tr·∫£ v·ªÅ CH·ªà C√ÅC S·ªê, m·ªói d√≤ng 1 s·ªë, theo th·ª© t·ª±:
1
0
-1
..."""

            try:
                response = self.gemini_model.generate_content(
                    prompt,
                    generation_config=genai.types.GenerationConfig(
                        temperature=0.2,
                        max_output_tokens=min(100, len(comments_list) * 5),  # T·ªëi ∆∞u tokens
                    )
                )
                
                result_text = response.text.strip()
                
                # Parse k·∫øt qu·∫£ - t√¨m t·∫•t c·∫£ s·ªë
                import re
                numbers = re.findall(r'-?\d+', result_text)
                
                # Map k·∫øt qu·∫£ v·ªÅ batch
                result_idx = 0
                for text in batch_texts:
                    if pd.isna(text) or not str(text).strip():
                        batch_scores.append(0)
                    elif result_idx < len(numbers):
                        score = int(numbers[result_idx])
                        if score in [-1, 0, 1]:
                            batch_scores.append(score)
                        else:
                            # Fallback
                            pos_keyword_score, neg_keyword_score, neutral_indicator = self._check_keywords_and_emojis(str(text))
                            if neg_keyword_score > 0.4:
                                batch_scores.append(-1)
                            elif pos_keyword_score > 0.4 and neg_keyword_score < 0.3:
                                batch_scores.append(1)
                            elif neutral_indicator > 0.6:
                                batch_scores.append(0)
                            else:
                                batch_scores.append(0 if abs(pos_keyword_score - neg_keyword_score) < 0.2 else (1 if pos_keyword_score > neg_keyword_score else -1))
                        result_idx += 1
                    else:
                        # Kh√¥ng ƒë·ªß k·∫øt qu·∫£, d√πng fallback
                        pos_keyword_score, neg_keyword_score, neutral_indicator = self._check_keywords_and_emojis(str(text))
                        if neg_keyword_score > 0.4:
                            batch_scores.append(-1)
                        elif pos_keyword_score > 0.4 and neg_keyword_score < 0.3:
                            batch_scores.append(1)
                        else:
                            batch_scores.append(0 if neutral_indicator > 0.6 else (1 if pos_keyword_score > neg_keyword_score else -1))
                
                results.extend(batch_scores)
                
                # Delay nh·ªè gi·ªØa c√°c batch
                time.sleep(0.2)  # 200ms gi·ªØa c√°c batch thay v√¨ t·ª´ng c√°i
                
            except Exception as e:
                print(f"L·ªói Gemini batch: {str(e)[:100]}")
                # Fallback: ph√¢n t√≠ch t·ª´ng c√°i b·∫±ng keyword
                for text in batch_texts:
                    if pd.isna(text) or not str(text).strip():
                        results.append(0)
                    else:
                        pos_keyword_score, neg_keyword_score, neutral_indicator = self._check_keywords_and_emojis(str(text))
                        if neg_keyword_score > 0.4:
                            results.append(-1)
                        elif pos_keyword_score > 0.4 and neg_keyword_score < 0.3:
                            results.append(1)
                        elif neutral_indicator > 0.6:
                            results.append(0)
                        else:
                            results.append(0 if abs(pos_keyword_score - neg_keyword_score) < 0.2 else (1 if pos_keyword_score > neg_keyword_score else -1))
        
        return np.array(results)
    
    def analyze_batch(self, texts, batch_size=32, progress_callback=None):
        """
        Ph√¢n t√≠ch sentiment cho nhi·ªÅu texts (nhanh h∆°n)
        
        Args:
            texts: List ho·∫∑c Series c√°c texts
            batch_size: S·ªë l∆∞·ª£ng texts x·ª≠ l√Ω c√πng l√∫c
            progress_callback: H√†m callback ƒë·ªÉ c·∫≠p nh·∫≠t progress (current, total)
            
        Returns:
            numpy array: M·∫£ng c√°c sentiment scores
        """
        # N·∫øu d√πng Gemini, s·ª≠ d·ª•ng batch processing
        if self.use_gemini and self.gemini_model:
            return self.analyze_batch_gemini(texts, batch_size=min(batch_size, 20), progress_callback=progress_callback)
        
        results = []
        total_batches = (len(texts) + batch_size - 1) // batch_size
        
        # X·ª≠ l√Ω theo batch ƒë·ªÉ tƒÉng t·ªëc
        # S·ª≠ d·ª•ng tqdm n·∫øu kh√¥ng c√≥ callback (cho CLI)
        if progress_callback is None:
            try:
                progress_range = tqdm(range(0, len(texts), batch_size), desc="Ph√¢n t√≠ch sentiment")
            except:
                progress_range = range(0, len(texts), batch_size)
        else:
            progress_range = range(0, len(texts), batch_size)
        
        for batch_idx, i in enumerate(progress_range):
            if progress_callback:
                progress_callback(batch_idx + 1, total_batches)
            batch = texts[i:i+batch_size].tolist()
            
            # X·ª≠ l√Ω t·ª´ng text trong batch ƒë·ªÉ tr√°nh l·ªói
            for text in batch:
                if pd.isna(text) or not str(text).strip():
                    results.append(0)
                    continue
                
                try:
                    # S·ª≠ d·ª•ng analyze_text ƒë·ªÉ c√≥ logic c·∫£i thi·ªán
                    sentiment_score = self.analyze_text(text)
                    results.append(sentiment_score)
                        
                except Exception as e:
                    # N·∫øu l·ªói, m·∫∑c ƒë·ªãnh l√† neutral
                    print(f"L·ªói khi ph√¢n t√≠ch: {str(e)[:100]}")
                    results.append(0)
        
        return np.array(results)
    
    def process_csv(self, input_file, output_file=None, text_column='text', trust_column='sentiment', batch_size=32):
        """
        X·ª≠ l√Ω file CSV: ƒë·ªçc, ph√¢n t√≠ch sentiment, v√† l∆∞u k·∫øt qu·∫£
        
        Args:
            input_file: ƒê∆∞·ªùng d·∫´n file CSV ƒë·∫ßu v√†o
            output_file: ƒê∆∞·ªùng d·∫´n file CSV ƒë·∫ßu ra (n·∫øu None th√¨ ghi ƒë√® file ƒë·∫ßu v√†o)
            text_column: T√™n c·ªôt ch·ª©a text
            trust_column: T√™n c·ªôt sentiment c·∫ßn t·∫°o/c·∫≠p nh·∫≠t (m·∫∑c ƒë·ªãnh: 'sentiment')
            batch_size: S·ªë l∆∞·ª£ng texts x·ª≠ l√Ω c√πng l√∫c
        """
        print(f"ƒêang ƒë·ªçc file: {input_file}")
        df = pd.read_csv(input_file)
        
        print(f"T·ªïng s·ªë d√≤ng: {len(df)}")
        print(f"C·ªôt text c√≥ {df[text_column].notna().sum()} gi√° tr·ªã kh√¥ng r·ªóng")
        
        # Ki·ªÉm tra xem c·ªôt sentiment ƒë√£ t·ªìn t·∫°i ch∆∞a, n·∫øu kh√¥ng th√¨ th√™m v√†o cu·ªëi
        if trust_column not in df.columns:
            df[trust_column] = None
        
        # L·ªçc c√°c d√≤ng c·∫ßn ph√¢n t√≠ch (ch∆∞a c√≥ sentiment ho·∫∑c sentiment r·ªóng)
        mask = df[trust_column].isna() | (df[trust_column] == '')
        texts_to_analyze = df.loc[mask, text_column]
        
        if len(texts_to_analyze) == 0:
            print("T·∫•t c·∫£ c√°c d√≤ng ƒë√£ c√≥ sentiment score. Kh√¥ng c·∫ßn ph√¢n t√≠ch th√™m.")
            return df
        
        print(f"S·ªë d√≤ng c·∫ßn ph√¢n t√≠ch: {len(texts_to_analyze)}")
        
        # Ph√¢n t√≠ch sentiment
        print("B·∫Øt ƒë·∫ßu ph√¢n t√≠ch sentiment...")
        sentiment_scores = self.analyze_batch(texts_to_analyze, batch_size=batch_size)
        
        # C·∫≠p nh·∫≠t c·ªôt sentiment
        df.loc[mask, trust_column] = sentiment_scores
        
        # Th·ªëng k√™ k·∫øt qu·∫£
        print("\n=== Th·ªëng k√™ k·∫øt qu·∫£ ===")
        print(f"T√≠ch c·ª±c (1): {(df[trust_column] == 1).sum()} ({((df[trust_column] == 1).sum() / len(df) * 100):.2f}%)")
        print(f"Trung t√≠nh (0): {(df[trust_column] == 0).sum()} ({((df[trust_column] == 0).sum() / len(df) * 100):.2f}%)")
        print(f"Ti√™u c·ª±c (-1): {(df[trust_column] == -1).sum()} ({((df[trust_column] == -1).sum() / len(df) * 100):.2f}%)")
        
        # L∆∞u file
        if output_file is None:
            output_file = input_file
        
        print(f"\nƒêang l∆∞u k·∫øt qu·∫£ v√†o: {output_file}")
        df.to_csv(output_file, index=False, encoding='utf-8-sig')
        print("Ho√†n th√†nh!")
        
        return df
    
    def process_csv_dataframe(self, df, text_column='text', trust_column='sentiment', batch_size=32):
        """
        X·ª≠ l√Ω DataFrame tr·ª±c ti·∫øp: ph√¢n t√≠ch sentiment v√† th√™m c·ªôt sentiment
        
        Args:
            df: DataFrame c·∫ßn x·ª≠ l√Ω
            text_column: T√™n c·ªôt ch·ª©a text
            trust_column: T√™n c·ªôt sentiment c·∫ßn t·∫°o/c·∫≠p nh·∫≠t (m·∫∑c ƒë·ªãnh: 'sentiment')
            batch_size: S·ªë l∆∞·ª£ng texts x·ª≠ l√Ω c√πng l√∫c
            
        Returns:
            DataFrame: DataFrame ƒë√£ ƒë∆∞·ª£c th√™m c·ªôt sentiment
        """
        # Ki·ªÉm tra xem c·ªôt sentiment ƒë√£ t·ªìn t·∫°i ch∆∞a, n·∫øu kh√¥ng th√¨ th√™m v√†o cu·ªëi
        if trust_column not in df.columns:
            df[trust_column] = None
        
        # L·ªçc c√°c d√≤ng c·∫ßn ph√¢n t√≠ch (ch∆∞a c√≥ sentiment ho·∫∑c sentiment r·ªóng)
        mask = df[trust_column].isna() | (df[trust_column] == '')
        texts_to_analyze = df.loc[mask, text_column]
        
        if len(texts_to_analyze) == 0:
            return df
        
        # L·∫•y progress callback n·∫øu c√≥
        progress_callback = getattr(self, 'progress_callback', None)
        
        # Ph√¢n t√≠ch sentiment
        sentiment_scores = self.analyze_batch(texts_to_analyze, batch_size=batch_size, progress_callback=progress_callback)
        
        # C·∫≠p nh·∫≠t c·ªôt sentiment
        df.loc[mask, trust_column] = sentiment_scores
        
        return df


def main():
    """H√†m main ƒë·ªÉ ch·∫°y tool"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Ph√¢n t√≠ch sentiment cho comments TikTok')
    parser.add_argument('--input', '-i', 
                       default='dataset_tiktok-comments-637video-scraper_2026-01-15.csv',
                       help='File CSV ƒë·∫ßu v√†o')
    parser.add_argument('--output', '-o', 
                       default=None,
                       help='File CSV ƒë·∫ßu ra (n·∫øu kh√¥ng ch·ªâ ƒë·ªãnh th√¨ ghi ƒë√® file ƒë·∫ßu v√†o)')
    parser.add_argument('--model', '-m',
                       default='cardiffnlp/twitter-roberta-base-sentiment-latest',
                       choices=['cardiffnlp/twitter-roberta-base-sentiment-latest',
                               'nlptown/bert-base-multilingual-uncased-sentiment'],
                       help='Model sentiment analysis')
    parser.add_argument('--batch-size', '-b',
                       type=int, default=32,
                       help='K√≠ch th∆∞·ªõc batch (m·∫∑c ƒë·ªãnh: 32)')
    parser.add_argument('--text-column', '-t',
                       default='text',
                       help='T√™n c·ªôt ch·ª©a text (m·∫∑c ƒë·ªãnh: text)')
    parser.add_argument('--trust-column', '-c',
                       default='sentiment',
                       help='T√™n c·ªôt sentiment (m·∫∑c ƒë·ªãnh: sentiment)')
    
    args = parser.parse_args()
    
    # Kh·ªüi t·∫°o analyzer
    analyzer = SentimentAnalyzer(model_name=args.model)
    
    # X·ª≠ l√Ω file
    analyzer.process_csv(
        input_file=args.input,
        output_file=args.output,
        text_column=args.text_column,
        trust_column=args.trust_column,
        batch_size=args.batch_size
    )


if __name__ == '__main__':
    main()
